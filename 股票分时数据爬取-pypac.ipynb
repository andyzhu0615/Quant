{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pypac import PACSession\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 300052 中青宝 fenshi stored!\n",
      "2: 688023 安恒信息 fenshi stored!\n",
      "3: 000951 中国重汽 fenshi stored!\n",
      "4: 300741 华宝股份 fenshi stored!\n",
      "5: 603822 嘉澳环保 fenshi stored!\n",
      "6: 002777 久远银海 fenshi stored!\n",
      "7: 300280 紫天科技 fenshi stored!\n",
      "8: 300161 华中数控 fenshi stored!\n",
      "9: 603897 长城科技 fenshi stored!\n",
      "10: 300212 易华录 fenshi stored!\n",
      "11: 002983 芯瑞达 fenshi stored!\n",
      "12: 603915 国茂股份 fenshi stored!\n",
      "13: 002126 银轮股份 fenshi stored!\n",
      "14: 600999 招商证券 fenshi stored!\n",
      "15: 002456 欧菲光 fenshi stored!\n",
      "16: 002475 立讯精密 fenshi stored!\n",
      "17: 603021 山东华鹏 fenshi stored!\n",
      "18: 300454 深信服 fenshi stored!\n",
      "19: 002152 广电运通 fenshi stored!\n",
      "20: 603818 曲美家居 fenshi stored!\n",
      "WELL DONE!!!\n"
     ]
    }
   ],
   "source": [
    "curr_time = datetime.datetime.now()\n",
    "hq_csv =  \"../Stock_data/hangqing/\" + \"hangqing_A_\" + str(curr_time.date()) + \".csv\"\n",
    "df1 = pd.read_csv(hq_csv,dtype={'f12':str})\n",
    "df1[['f12','f14', 'f13']].head(10)\n",
    "df1.set_index('f12', inplace=True)\n",
    "#df1.loc['300820', 'f13']\n",
    "#df1.index[:10]\n",
    "\n",
    "filed_num = 0\n",
    "\n",
    "for stock_code in df1.index[-40:-20]:\n",
    "    \n",
    "    market_id = df1.loc[stock_code, 'f13'] #上证是1，深证是0\n",
    "    if str(market_id) == '0':\n",
    "        stock_id = stock_code + '2' #上证是1，深证是2\n",
    "    else:\n",
    "        stock_id = stock_code + '1' #上证是1，深证是2\n",
    "    \n",
    "    stock_name = df1.loc[stock_code, 'f14']\n",
    "    csv_file_name = \"../Stock_data/fenshi/\" + \"fenshi_\" + stock_code + \"_\" + stock_name + \"_\" + str(curr_time.date()) + \".csv\"\n",
    "\n",
    "    for page_num in range(50):\n",
    "        try:\n",
    "            cookies = {\n",
    "                'em_hq_fls': 'js',\n",
    "                'pgv_pvi': '9744040960',\n",
    "                '_qddaz': 'QD.efn5wx.2y13rz.kbiype8t',\n",
    "                'intellpositionL': '720.95px',\n",
    "                'cowminicookie': 'true',\n",
    "                'emshistory': '^%^5B^%^22600519^%^22^%^5D',\n",
    "                'intellpositionT': '755px',\n",
    "                'qgqp_b_id': '3b5494631b0d78184891d0de53c4b3d9',\n",
    "                'st_si': '81244739108722',\n",
    "                'st_asi': 'delete',\n",
    "                '_sm_au_c': 'kLQABAOhavxwaGMtlop7idfc5VbaufLUcxaJVNQw0aBAgAAAAXYqAxNyvGhuw4qcGTDpRh0vz6imEFA2Tbt8n3TUV7ks=',\n",
    "                'st_pvi': '20795103616993',\n",
    "                'st_sp': '2020-06-17^%^2014^%^3A02^%^3A47',\n",
    "                'st_inirUrl': 'https^%^3A^%^2F^%^2Fcn.bing.com^%^2F',\n",
    "                'st_sn': '26',\n",
    "                'st_psi': '20200629111105268-0-8277370083',\n",
    "                'HAList': 'a-sh-601865-^%^u798F^%^u83B1^%^u7279^%^2Ca-sz-002813-^%^u8DEF^%^u7545^%^u79D1^%^u6280^%^2Ca-sh-600956-N^%^u65B0^%^u5929^%^2Ca-sh-600519-^%^u8D35^%^u5DDE^%^u8305^%^u53F0^%^2Ca-sz-000858-^%^u4E94^%^20^%^u7CAE^%^20^%^u6DB2^%^2Ca-sz-002129-^%^u4E2D^%^u73AF^%^u80A1^%^u4EFD^%^2Ca-sh-603365-^%^u6C34^%^u661F^%^u5BB6^%^u7EBA^%^2Ca-sh-600918-^%^u4E2D^%^u6CF0^%^u8BC1^%^u5238',\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                'Proxy-Connection': 'keep-alive',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36',\n",
    "                'Accept': '*/*',\n",
    "                'Referer': 'http://quote.eastmoney.com/f1.html?code=601865^&market=1',\n",
    "                'Accept-Language': 'en-US,en;q=0.9',\n",
    "            }\n",
    "\n",
    "            # params = (\n",
    "            #     ('pagesize', '144^'),\n",
    "            #     ('ut', '7eea3edcaed734bea9cbfc24409ed989^'),\n",
    "            #     ('dpt', 'wzfscj^'),\n",
    "            #     ('cb', 'jQuery1123002362902683982293_1593400265041^'),\n",
    "            #     ('pageindex', '17^'),\n",
    "            #     ('id', '6018651^'),\n",
    "            #     ('sort', '1^'),\n",
    "            #     ('ft', '1^'),\n",
    "            #     ('code', '601865^'),\n",
    "            #     ('market', '1^'),\n",
    "            #     ('_', '1593400265053'),\n",
    "            # )\n",
    "\n",
    "            params = (\n",
    "                ('pagesize', '144'),\n",
    "                ('ut', '7eea3edcaed734bea9cbfc24409ed989'),\n",
    "                ('dpt', 'wzfscj'),\n",
    "                #('cb', 'jQuery1123002362902683982293_1593400265041'),\n",
    "                ('pageindex', str(page_num)),\n",
    "                ('id', str(stock_id)),\n",
    "                ('sort', '1'),\n",
    "                ('ft', '1'),\n",
    "                ('code', str(stock_code)),\n",
    "                ('market', str(market_id)),\n",
    "                ('_', '1593400265053'),\n",
    "             )\n",
    "\n",
    "\n",
    "            #print(params)\n",
    "            session = PACSession()\n",
    "            response = session.get('http://push2ex.eastmoney.com/getStockFenShi', headers=headers, params=params, cookies=cookies, verify=False)\n",
    "            #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi',params=params)\n",
    "            #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi?pagesize=144&ut=7eea3edcaed734bea9cbfc24409ed989&dpt=wzfscj&pageindex=7&id=6018651&sort=1&ft=1&code=601865&market=1&_=1593400265053')\n",
    "\n",
    "            #NB. Original query string below. It seems impossible to parse and\n",
    "            #reproduce query strings 100% accurately so the one below is given\n",
    "            #in case the reproduced version is not \"correct\".\n",
    "            #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi?pagesize=144^&ut=7eea3edcaed734bea9cbfc24409ed989^&dpt=wzfscj^&pageindex=10^&id=6018651^&sort=1^&ft=1^&code=601865^&market=1^&_=1593400265053')\n",
    "            #response.text\n",
    "\n",
    "            dict = json.loads(response.text)['data']['data']\n",
    "            #stock_name = json.loads(response.text)['data']['n']\n",
    "            df = json_normalize(dict)\n",
    "            #df.tail(10)\n",
    "            timelst = pd.to_datetime(df['t'],format='%H%M%S')\n",
    "            #timelst.dt.time\n",
    "            df['t'] = timelst.dt.time\n",
    "            df['p'] = df['p']/1000\n",
    "            \n",
    "            #csv_file_name = \"../Stock_data/fenshi/\" + \"fenshi_\" + stock_code + \"_\" + stock_name + \"_\" + str(curr_time.date()) + \".csv\"\n",
    "\n",
    "            if page_num == 0:\n",
    "                df.to_csv(csv_file_name, index=False, encoding=\"utf_8_sig\")\n",
    "            else:\n",
    "                df.to_csv(csv_file_name, index=False, header=False, mode='a', encoding=\"utf_8_sig\")\n",
    "            #print(\"Page \" + str(page_num) + ' stored!')\n",
    "\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    filed_num+= 1\n",
    "    #print(\"\\r\" + str(filed_num) + \": \" + stock_code + \" \" + stock_name + \" fenshi stored!\", end=\"\")\n",
    "    print(str(filed_num) + \": \" + stock_code + \" \" + stock_name + \" fenshi stored!\")\n",
    "\n",
    "print(\"WELL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t: 时间，p：元*1000，v:手数 bs: 1代表卖方主动(绿色)；2代表买方主动（红色）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以下载全的版本（2020701午）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180: 600817 ST宏盛 fenshi stored!!\n",
      "exit_flag = 1\n",
      "WELL DONE!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from pypac import PACSession\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import datetime\n",
    "\n",
    "curr_time = datetime.datetime.now()\n",
    "hq_csv =  \"../Stock_data/hangqing/\" + \"hangqing_A_\" + str(curr_time.date()) + \".csv\"\n",
    "df1 = pd.read_csv(hq_csv,dtype={'f12':str})\n",
    "\n",
    "file_dir = \"../Stock_data/fenshi/\"\n",
    "\n",
    "exit_flag = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        namelist = []\n",
    "        for name in files:\n",
    "            #print(os.path.join(root, name))\n",
    "            #print(name[7:13])\n",
    "            namelist.append(name[7:13])\n",
    "\n",
    "    df1 = df1[~df1['f12'].isin(namelist)]\n",
    "    \n",
    "    if len(df1['f12']) < 1:\n",
    "        break\n",
    "    \n",
    "    if exit_flag>5:\n",
    "        df1.to_csv(\"../Stock_data/hangqing/na_stock_list_\" + str(curr_time.date()) + \".csv\")\n",
    "        exit()\n",
    "    \n",
    "    #df1[['f12','f14', 'f13']].head(10)\n",
    "    #df1.set_index('f12', inplace=True)\n",
    "    #df1.loc['300820', 'f13']\n",
    "    #df1.index[:10]\n",
    "\n",
    "    filed_num = len(namelist)\n",
    "\n",
    "    for stock_code in df1['f12']:  \n",
    "\n",
    "        #market_id = df1.loc[stock_code, 'f13'] #上证是1，深证是0\n",
    "        market_id_se = df1[df1['f12'] == stock_code]['f13']\n",
    "        market_id = market_id_se.iloc[0]\n",
    "\n",
    "        if str(market_id) == '0':\n",
    "            stock_id = stock_code + '2' #上证是1，深证是2\n",
    "        else:\n",
    "            stock_id = stock_code + '1' #上证是1，深证是2\n",
    "\n",
    "        #stock_name = df1.loc[stock_code, 'f14']\n",
    "        stock_name_se = df1[df1['f12'] == stock_code]['f14']\n",
    "        stock_name = stock_name_se.iloc[0]\n",
    "        if stock_name[0] == \"*\":\n",
    "            stock_name = stock_name[1:]\n",
    "\n",
    "        csv_file_name = \"../Stock_data/fenshi/\" + \"fenshi_\" + stock_code + \"_\" + stock_name + \"_\" + str(curr_time.date()) + \".csv\"\n",
    "\n",
    "        for page_num in range(50):\n",
    "            try:\n",
    "                cookies = {\n",
    "                    'em_hq_fls': 'js',\n",
    "                    'pgv_pvi': '9744040960',\n",
    "                    '_qddaz': 'QD.efn5wx.2y13rz.kbiype8t',\n",
    "                    'intellpositionL': '720.95px',\n",
    "                    'cowminicookie': 'true',\n",
    "                    'emshistory': '^%^5B^%^22600519^%^22^%^5D',\n",
    "                    'intellpositionT': '755px',\n",
    "                    'qgqp_b_id': '3b5494631b0d78184891d0de53c4b3d9',\n",
    "                    'st_si': '81244739108722',\n",
    "                    'st_asi': 'delete',\n",
    "                    '_sm_au_c': 'kLQABAOhavxwaGMtlop7idfc5VbaufLUcxaJVNQw0aBAgAAAAXYqAxNyvGhuw4qcGTDpRh0vz6imEFA2Tbt8n3TUV7ks=',\n",
    "                    'st_pvi': '20795103616993',\n",
    "                    'st_sp': '2020-06-17^%^2014^%^3A02^%^3A47',\n",
    "                    'st_inirUrl': 'https^%^3A^%^2F^%^2Fcn.bing.com^%^2F',\n",
    "                    'st_sn': '26',\n",
    "                    'st_psi': '20200629111105268-0-8277370083',\n",
    "                    'HAList': 'a-sh-601865-^%^u798F^%^u83B1^%^u7279^%^2Ca-sz-002813-^%^u8DEF^%^u7545^%^u79D1^%^u6280^%^2Ca-sh-600956-N^%^u65B0^%^u5929^%^2Ca-sh-600519-^%^u8D35^%^u5DDE^%^u8305^%^u53F0^%^2Ca-sz-000858-^%^u4E94^%^20^%^u7CAE^%^20^%^u6DB2^%^2Ca-sz-002129-^%^u4E2D^%^u73AF^%^u80A1^%^u4EFD^%^2Ca-sh-603365-^%^u6C34^%^u661F^%^u5BB6^%^u7EBA^%^2Ca-sh-600918-^%^u4E2D^%^u6CF0^%^u8BC1^%^u5238',\n",
    "                }\n",
    "\n",
    "                headers = {\n",
    "                    'Proxy-Connection': 'keep-alive',\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36',\n",
    "                    'Accept': '*/*',\n",
    "                    'Referer': 'http://quote.eastmoney.com/f1.html?code=601865^&market=1',\n",
    "                    'Accept-Language': 'en-US,en;q=0.9',\n",
    "                }\n",
    "\n",
    "                # params = (\n",
    "                #     ('pagesize', '144^'),\n",
    "                #     ('ut', '7eea3edcaed734bea9cbfc24409ed989^'),\n",
    "                #     ('dpt', 'wzfscj^'),\n",
    "                #     ('cb', 'jQuery1123002362902683982293_1593400265041^'),\n",
    "                #     ('pageindex', '17^'),\n",
    "                #     ('id', '6018651^'),\n",
    "                #     ('sort', '1^'),\n",
    "                #     ('ft', '1^'),\n",
    "                #     ('code', '601865^'),\n",
    "                #     ('market', '1^'),\n",
    "                #     ('_', '1593400265053'),\n",
    "                # )\n",
    "\n",
    "                params = (\n",
    "                    ('pagesize', '144'),\n",
    "                    ('ut', '7eea3edcaed734bea9cbfc24409ed989'),\n",
    "                    ('dpt', 'wzfscj'),\n",
    "                    #('cb', 'jQuery1123002362902683982293_1593400265041'),\n",
    "                    ('pageindex', str(page_num)),\n",
    "                    ('id', str(stock_id)),\n",
    "                    ('sort', '1'),\n",
    "                    ('ft', '1'),\n",
    "                    ('code', str(stock_code)),\n",
    "                    ('market', str(market_id)),\n",
    "                    ('_', '1593400265053'),\n",
    "                 )\n",
    "\n",
    "\n",
    "                #print(params)\n",
    "                session = PACSession()\n",
    "                response = session.get('http://push2ex.eastmoney.com/getStockFenShi', headers=headers, params=params, cookies=cookies, verify=False)\n",
    "                #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi',params=params)\n",
    "                #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi?pagesize=144&ut=7eea3edcaed734bea9cbfc24409ed989&dpt=wzfscj&pageindex=7&id=6018651&sort=1&ft=1&code=601865&market=1&_=1593400265053')\n",
    "\n",
    "                #NB. Original query string below. It seems impossible to parse and\n",
    "                #reproduce query strings 100% accurately so the one below is given\n",
    "                #in case the reproduced version is not \"correct\".\n",
    "                #response = requests.get('http://push2ex.eastmoney.com/getStockFenShi?pagesize=144^&ut=7eea3edcaed734bea9cbfc24409ed989^&dpt=wzfscj^&pageindex=10^&id=6018651^&sort=1^&ft=1^&code=601865^&market=1^&_=1593400265053')\n",
    "                #response.text\n",
    "\n",
    "                dict = json.loads(response.text)['data']['data']\n",
    "                #stock_name = json.loads(response.text)['data']['n']\n",
    "                df = json_normalize(dict)\n",
    "                #df.tail(10)\n",
    "                timelst = pd.to_datetime(df['t'],format='%H%M%S')\n",
    "                #timelst.dt.time\n",
    "                df['t'] = timelst.dt.time\n",
    "                df['p'] = df['p']/1000\n",
    "\n",
    "                #csv_file_name = \"../Stock_data/fenshi/\" + \"fenshi_\" + stock_code + \"_\" + stock_name + \"_\" + str(curr_time.date()) + \".csv\"\n",
    "\n",
    "                if page_num == 0:\n",
    "                    df.to_csv(csv_file_name, index=False, encoding=\"utf_8_sig\")\n",
    "                else:\n",
    "                    df.to_csv(csv_file_name, index=False, header=False, mode='a', encoding=\"utf_8_sig\")\n",
    "                #print(\"Page \" + str(page_num) + ' stored!')\n",
    "\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        filed_num+= 1\n",
    "        print(\"\\r\" + str(filed_num) + \": \" + stock_code + \" \" + stock_name + \" fenshi stored!\", end=\"\")\n",
    "        #print(str(filed_num) + \": \" + stock_code + \" \" + stock_name + \" fenshi stored!\")\n",
    "    \n",
    "    exit_flag+= 1\n",
    "    \n",
    "    print('\\nexit_flag = ' + str(exit_flag))\n",
    "    #print(\"\\nGOOD!\")\n",
    "    \n",
    "print(\"WELL DONE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扫描数据目录中的文件名，将已有的股票从df1中去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      688528\n",
       "1      300846\n",
       "2      688520\n",
       "3      688278\n",
       "4      002069\n",
       "        ...  \n",
       "175    600021\n",
       "176    603896\n",
       "177    300639\n",
       "178    002467\n",
       "179    600817\n",
       "Name: f12, Length: 180, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from pypac import PACSession\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "file_dir = \"../Stock_data/fenshi/\"\n",
    "for root, dirs, files in os.walk(file_dir):\n",
    "    namelist = []\n",
    "    for name in files:\n",
    "        #print(os.path.join(root, name))\n",
    "        #print(name[7:13])\n",
    "        namelist.append(name[7:13])\n",
    "\n",
    "curr_time = datetime.datetime.now()\n",
    "#hq_csv =  \"../Stock_data/hangqing/\" + \"hangqing_A_\" + str(curr_time.date()) + \".csv\" #hangqing_A_2020-06-30\n",
    "hq_csv =  \"../Stock_data/hangqing/\" + \"hangqing_A_\" + \"2020-07-01\" + \".csv\"\n",
    "df1 = pd.read_csv(hq_csv,dtype={'f12':str})\n",
    "#df1.set_index('f12', inplace=True)\n",
    "\n",
    "df2 = df1[~df1['f12'].isin(namelist)] #从df1中去掉某些行，这些行中的'f12'列中包含namelist中的元素\n",
    "\n",
    "#df1['f12'].isin(namelist).to_csv('111111.csv')\n",
    "                \n",
    "#df1['f12']\n",
    "# stock_code = '688196'\n",
    "# market_id = df1[df1['f12'] == stock_code]['f13']\n",
    "\n",
    "#market_id = df1.loc[stock_code, 'f13']\n",
    "\n",
    "# market_id.iloc[0]\n",
    "#df2.to_csv(\"nan_stock_list1.csv\")\n",
    "print(len(df1['f12']))\n",
    "# print(len(df2))\n",
    "print(len(namelist))\n",
    "# namelist\n",
    "df2['f12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
